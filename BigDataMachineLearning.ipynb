{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# CZĘŚĆ 1 - OPTYMALIZACJA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## OPIS ZESTAWU DANYCH\n",
    "Dane składają się z informacji o przylotach i odlotach wszystkich lotów komercyjnych w USA od października 1987 do kwietnia 2008 – przede wszystkim o ich opóźnieniach. \\\n",
    "Zbiór danych jest bardzo duży (120mln rekordów, 12GB danych) – na potrzeby projektu wykorzystamy jedynie dane z roku 2007 co ograniczy rozmiar przetwarzanych danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import pyarrow as pa\n",
    "from matplotlib.pyplot import figure\n",
    "from matplotlib import pyplot as plt\n",
    "import statistics\n",
    "from sklearn.impute import KNNImputer\n",
    "import seaborn as sns\n",
    "import glob\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import isnull, when, count, col, hour, mean, lit, stddev,abs\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.regression import LinearRegression, RandomForestRegressor, DecisionTreeRegressor\n",
    "from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier, GBTClassifier, MultilayerPerceptronClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### OPIS KLAS\n",
    "W sumie klas jest 29, opisują one następujące informacje:\n",
    "* rok\n",
    "* miesiąc\n",
    "* dzień miesiąca\n",
    "* dzień tygodnia\n",
    "* rzeczywisty czas odlotu\n",
    "* zaplanowany czas odlotu\n",
    "* rzeczywisty czas przylotu\n",
    "* zaplanowany czas przylotu\n",
    "* kod przewoźnika\n",
    "* numer lotu\n",
    "* numer ogonowy samolotu\n",
    "* całkowity czas lotu w minutach\n",
    "* rzeczywisty czas lotu\n",
    "* całkowity czas w powietrzu\n",
    "* opóźnienie lotu w minutach\n",
    "* miejsce startu\n",
    "* miejsce docelowe\n",
    "* odległość w milach\n",
    "* dane dotyczące przyjazdu taksówki\n",
    "* informacje o tym czy lot był anulowany\n",
    "* powód anulowania (pogoda, przewoźnik, ochrona, NAS)\n",
    "* przekierowanie (tak/nie)\n",
    "* opóźnienie przewoźnika w minutach\n",
    "* opóźnienie pogodowe w minutach\n",
    "* opóźnienie NAS w minutach\n",
    "* opóźnienie z powodów bezpieczeństwa w minutach\n",
    "* sumaryczne opóźnienie w minutach\n",
    "\n",
    "Celem projektu jest przewidywanie sumarycznego opóźnienia samolotu - zmienna objaśniana - na podstawie podzbioru pozostałych kolumn (zmiennych objaśniających), które wybierzemy na podstawie dalszej analizy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#TO DO dodać czytanie z kilku plików na raz\n",
    "# data = pd.concat([pd.read_csv(f) for f in glob.glob('./data/*.csv')], ignore_index = True)\n",
    "data = pd.read_parquet('2007.gzip')\n",
    "with pd.option_context('display.float_format', '{:.2f}'.format, 'display.max_rows', None, 'display.max_columns', None):\n",
    "\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['DepTime', 'CRSDepTime', 'ArrTime', 'CRSArrTime']:\n",
    "    data[column] = data[column] // 100 + (data[column] % 100) / 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "  Jak widać w powyższej tabeli, niektóre kolumny zawierają dane tekstowe - UniqueCarrier, TailNum, Origin, Dest i CancellationCode. \\\n",
    "Z racji tego, że w projekcie chcielibyśmy się skupić na powiązaniach między opóźnieniami/odwołaniami lotów, a momentem ich odbywania, część danych będzie nam zbędna. Dlatego też zdecydowaliśmy się na usunięcie kolumn:\n",
    "- UniqueCarrier - indywidualny kod przewoźnika\n",
    "- TailNum - numer ogonowy\n",
    "- Origin - miejsce rozpoczęcia podróży\n",
    "- Dest - cel podróży\n",
    "- CancellationCode - kod odwołania\n",
    "\n",
    "Ponadto usuwamy także poniższe kolumny:\n",
    "- FlightNum - ponieważ pełni on rolę numeru ID, więc nie będzie miało większego sensu uwzględnianie go w modelu.\n",
    "- TaxiIn, TaxiOut - ponieważ dane na temat taksówki naszym zdaniem nie mają wpływu na opóźnienie/odwołanie lotu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.drop('UniqueCarrier', inplace=True, axis =1)\n",
    "data.drop('TailNum', inplace=True, axis =1)\n",
    "data.drop('Origin', inplace=True, axis =1)\n",
    "data.drop('Dest', inplace=True, axis =1)\n",
    "data.drop('CancellationCode', inplace=True, axis =1)\n",
    "data.drop('FlightNum', inplace=True, axis =1)\n",
    "data.drop('TaxiIn', inplace=True, axis =1)\n",
    "data.drop('TaxiOut', inplace=True, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with pd.option_context('display.float_format', '{:.2f}'.format, 'display.max_rows', None, 'display.max_columns', None):\n",
    "\n",
    "display(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Jak widać w powyższej tabeli dane obejmują okres od stycznia do czerwca 2007 i są dość równo rozłożone w tym okresie - średni miesiąc to między marcem a kwietniem, dni miesiąca oraz dni tygodnia mają równo rozłożone kwartyle. \\\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## WIZUALIZACJA DANYCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### BOXPLOTY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_for_visualisation = [column for column in data.columns if column != 'Year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=5, ncols=4, figsize=(20, 20))\n",
    "axes = axes.flatten()\n",
    "for i, column in enumerate(columns_for_visualisation):\n",
    "    sns.boxplot(data[column], ax=axes[i], orient='v')\n",
    "    axes[i].set_title(column, fontsize=15)\n",
    "    axes[i].set_ylabel('')\n",
    "    axes[i].set_xticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4,4, figsize=(10,10))\n",
    "for c, i in zip(data.columns, range(0,len(data.columns))):\n",
    "    a = data.boxplot(column=c, ax=axes.flatten()[i])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### TO DO: Dodać komentarz dotyczący boxplotów"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### HISTOGRAMY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=5, figsize=(20, 10))\n",
    "axes = axes.flatten()\n",
    "for i, column in enumerate(columns_for_visualisation):\n",
    "    sns.histplot(data[column], ax=axes[i], bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 6, figsize=(10,10))\n",
    "for c, i in zip(data.columns, range(0,24)):\n",
    "    a = data.hist(column=c, ax=axes.flatten()[i], log= True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### TO DO: Dodać komentarz dotyczący histogramów"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### SCATTER PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_for_scatter = ['DepTime', 'CRSDepTime',\n",
    "       'ArrTime', 'CRSArrTime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#scatter plot matrix\n",
    "sns.pairplot(data, vars=columns_for_scatter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### TO DO: Dodać komentarz dotyczący scatterplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## PROBLEMY Z DANYMI - DANE BRAKUJĄCE, NIEPRAWIDŁOWE, ODSTAJĄCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### SPRAWDZENIE POPRAWNOŚCI TYPÓW DANYCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table = pa.Table.from_pandas(data)\n",
    "print(table.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Jak widać wyżej - wszystkie dane występują w poprawnym formacie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### NAPRAWA WIERSZY Z PUSTYMI DANYMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Obliczenie ilosci pustych danych\n",
    "# Obliczenie ilosci pustych danych\n",
    "np.sum(data.isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sizeBeforeDeleteNull= data.count()\n",
    "dataWithoutNull = data.dropna()\n",
    "sizeAfterDeleteNull =  dataWithoutNull.count()\n",
    "print(\"Usunieto: \", sizeBeforeDeleteNull - sizeAfterDeleteNull)\n",
    "\n",
    "print(\"Percent od reduced rows: \", 100*sum(sizeBeforeDeleteNull - sizeAfterDeleteNull)/sum(sizeBeforeDeleteNull))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### TO DO: ZMIENIC SPOSÓB RADZENIA SOBIE Z PUSTYMI DANYMI\n",
    "### TO DO: Dodać komentarz dotyczący danych pustych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### USUWANIE DANYCH ODSTAJĄCYCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sizeBefore = np.shape(data)[0]\n",
    "for col in data.columns:\n",
    "    data = data[np.abs(data[col]-data[col].mean()) <= (3*data[col].std())]\n",
    "sizeAfter =  np.shape(data)[0]\n",
    "print(\"Count of reduced rows: \", sizeBefore - sizeAfter)\n",
    "print(\"Percent od reduced rows: \", 100*(sizeBefore - sizeAfter)/sizeBefore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### TO DO: Dodać komentarz dotyczący danych odstających"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# KORELACJE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sns.pairplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20), dpi=80)\n",
    "corrMatrix = data.corr()\n",
    "sns.heatmap(corrMatrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### TO DO: Dodać komentarz dotyczący korelacji między danymi, ew dodać pairploty do wybranych danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO DO: \"Normalizacja danych (przedstawić wyniki min-max i standaryzacji). Zastanowić się nad zakresem skalowania danych\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## REDUKCJA WYMIAROWOŚCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### TO DO: Genetyczna optymalizacja cech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Genetyczna optymalizacja cech - NA RAZIE SAMA SELEKCJA NA PODSTAWIE KORELACJI\n",
    "pandasDF = data.filter([\"DayOfWeek\", \"DayofMonth\", \"Distance\", \"DepTime\", \"Cancelled\", \"Diverted\", \"LateAircraftDelay\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# PRZYGOTOWANIE MODELI REGRESJI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local\").appName(\"Project\").getOrCreate()\n",
    "sparkDF=spark.createDataFrame(pandasDF)\n",
    "sparkDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### PODZIAŁ DANYCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "vector = VectorAssembler(inputCols = ['DayOfWeek', 'DayofMonth', 'Distance', 'DepTime', 'Cancelled', 'Diverted'\n",
    "], outputCol = 'features')\n",
    "vectorData = vector.transform(sparkDF).select(['features', 'LateAircraftDelay'])\n",
    "vectorData.plot.bar(x = 'parameter', y= 'Coefficients')\n",
    "plt.show()\n",
    "\n",
    "vectorData.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df, test_df = sparkDF.randomSplit([0.7, 0.3])\n",
    "print(\"train.rows: \", train_df.count())\n",
    "print(\"test.rows: \", test_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### MIARY SKUTECZNOŚCI\n",
    "\n",
    "evaluatorRMSE = RegressionEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "evaluatorR2 = RegressionEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "\n",
    "\n",
    "def effectivenessMeasures(model, predictions):\n",
    "    print(\"Coefficients: \" + str(model.coefficients))\n",
    "    print(\"Intercept: \" + str(model.intercept))\n",
    "    print(predictions.show(5))\n",
    "    rmse = evaluatorRMSE.evaluate(predictions)\n",
    "    r2 = evaluatorR2.evaluate(predictions)\n",
    "    print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "    print(\"R2 on test data = %g\" % r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "linear_reg = LinearRegression(featuresCol = 'features', labelCol='label', maxIter=20, regParam=0.3, elasticNetParam=0.8)\n",
    "linear_model = linear_reg.fit(train_df)\n",
    "linear_predictions = linear_model.transform(test_df)\n",
    "effectivenessMeasures(linear_model, linear_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## RANDOM FOREST regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(featuresCol = 'features', labelCol='label')\n",
    "\n",
    "rf_model = rf.fit(train_df)\n",
    "rf_predictions = rf_model.transform(test_df)\n",
    "\n",
    "effectivenessMeasures(rf_model, rf_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## DECISION TREE REGRESSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeRegressor(featuresCol = 'features', labelCol='label')\n",
    "dt_model = dt.fit(train_df)\n",
    "dt_predictions = dt_model.transform(test_df)\n",
    "\n",
    "effectivenessMeasures(dt_model, dt_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# KLASYFIKACJA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MIARY SKUTECZNOŚCI - KLASYFIKACJA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def effectivenessMeasuresClassifier(predictions):\n",
    "    predictionCol = \"prediction\"\n",
    "    labelCol = \"Odwołane\"\n",
    "    acc=MulticlassClassificationEvaluator(predictionCol=predictionCol, labelCol=labelCol, metricName='accuracy').evaluate(predictions)\n",
    "    print(\"Prediction Accuracy: \", acc)\n",
    "\n",
    "    f1=MulticlassClassificationEvaluator(predictionCol=predictionCol, labelCol=labelCol, metricName='f1').evaluate(predictions)\n",
    "    print(\"F1: \", f1)\n",
    "\n",
    "    precision=MulticlassClassificationEvaluator(predictionCol=predictionCol, labelCol=labelCol, metricName='weightedPrecision').evaluate(predictions)\n",
    "    print(\"Precision: \", precision)\n",
    "\n",
    "    recall=MulticlassClassificationEvaluator(predictionCol=predictionCol, labelCol=labelCol, metricName='weightedRecall').evaluate(predictions)\n",
    "    print(\"Recall: \", recall)\n",
    "\n",
    "    y_pred=predictions.select(predictionCol).collect()\n",
    "    y_orig=predictions.select(labelCol).collect()\n",
    "\n",
    "    cm = confusion_matrix(y_orig, y_pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    return acc, f1, precision, recall\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### DECISION TREE CLASSIFIER"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "(trainingData, testData) = vectorData.randomSplit([0.7, 0.3])\n",
    "dtc = DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"SoilType\").fit(trainingData)\n",
    "pred = dtc.transform(testData)\n",
    "# pred.show()\n",
    "eff_dtc = effectivenessMeasuresClassifier(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### RANDOM FOREST CLASSIFIER"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(labelCol=\"SoilType\", featuresCol=\"features\", numTrees=10).fit(trainingData)\n",
    "pred = rfc.transform(testData)\n",
    "eff_rfc = effectivenessMeasuresClassifier(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MULTILAYER PERCEPTRON CLASSIFIER"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mpc = MultilayerPerceptronClassifier(labelCol=\"SoilType\", featuresCol=\"features\", numTrees=10).fit(trainingData)\n",
    "pred = mpc.transform(testData)\n",
    "eff_mpc = effectivenessMeasuresClassifier(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GBT CLASSIFIER"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbt = GBTClassifier(labelCol=\"SoilType\", featuresCol=\"features\", numTrees=10).fit(trainingData)\n",
    "pred = gbt.transform(testData)\n",
    "eff_gbt = effectivenessMeasuresClassifier(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ENSAMBLE CLASSIFICATOR - EXTRA TREES CLASSIFIER"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "etr = ExtraTreesClassifier(n_estimators = 100, criterion ='mse', max_features = \"auto\")\n",
    "etr_model = etr.fit(trainingData)\n",
    "pred = etr_model.transform(testData)\n",
    "eff_etr = effectivenessMeasuresClassifier(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ENSAMBLE CLASSIFICATOR - VOTING CLASSIFIER"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "lr_model = linear_model.LinearClassifier()\n",
    "dc_model = DecisionTreeClassifier()\n",
    "rf_model = RandomForestClassifier()\n",
    "estimators = [('lr', lr_model), ('dc', dc_model), ('rf', rf_model)]\n",
    "vc = VotingClassifier(estimators)\n",
    "vc_model = vc.fit(trainingData)\n",
    "pred = vc_model.transform(testData)\n",
    "vc_etr = effectivenessMeasuresClassifier(pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ENSAMBLE CLASSIFICATOR - STACKING CLASSIFIER"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "lr_model = linear_model.LinearClassifier()\n",
    "dc_model = DecisionTreeClassifier()\n",
    "rf_model = RandomForestClassifier()\n",
    "estimators = [('lr', lr_model), ('dc', dc_model), ('rf', rf_model)]\n",
    "sc = StackingClassifier(estimators)\n",
    "sc_model = sc.fit(trainingData)\n",
    "pred = sc_model.transform(testData)\n",
    "sc_etr = effectivenessMeasuresClassifier(pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## K-KROTNA WALIDAJA KRZYŻOWA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from random import randrange\n",
    "\n",
    "\n",
    "def cross_validation_split(data, folds):\n",
    "    dataset = data.copy().to_numpy()\n",
    "    dataset_split = list()\n",
    "    dataset_copy = list(dataset)\n",
    "    fold_size = int(len(dataset) / folds)\n",
    "    for i in range(folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size:\n",
    "            index = randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split.append(fold)\n",
    "    return dataset_split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TO DO STWORZYC FUNKCJE GENERUJACA WYNIKI"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: optymalizacja parametrow klasyfikatorow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.bar(trainingData.columns, etr.feature_importance)\n",
    "plt.xticks(rotation=40)\n",
    "plt.xlabel('Feature Labels')\n",
    "plt.ylabel('Feature Importances')\n",
    "plt.title('Comparison of different Feature Importances')\n",
    "plt.show()\n",
    "\n",
    "figure(figsize=(8, 6), dpi=80)\n",
    "\n",
    "corrMatrix = data.corr()\n",
    "sns.heatmap(corrMatrix, annot=True)\n",
    "plt.xlabel('Feature Labels')\n",
    "plt.ylabel('Feature Importances')\n",
    "plt.title('Comparison of different Feature Importances')\n",
    "plt.show()\n",
    "\n",
    "plt.bar(data.columns[:11], corrMatrix[\"cnt\"][:11])\n",
    "plt.xticks(rotation=40)\n",
    "plt.xlabel('Feature Labels')\n",
    "plt.ylabel('Feature Importances')\n",
    "plt.title('Comparison of different Feature Importances')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = read_data()\n",
    "\n",
    "size_before_opt = np.shape(data)[1] - 1\n",
    "print(\"Ilosc wymairów zmiennych zależnych przed optymalizacją: \", size_before_opt)\n",
    "data.drop('season', inplace=True, axis=1)\n",
    "data.drop('mnth', inplace=True, axis=1)\n",
    "data.drop('holiday', inplace=True, axis=1)\n",
    "data.drop('weathersit', inplace=True, axis=1)\n",
    "data.drop('temp', inplace=True, axis=1)\n",
    "data.drop('hum', inplace=True, axis=1)\n",
    "data.drop('windspeed', inplace=True, axis=1)\n",
    "size_after_opt = np.shape(data)[1] - 1\n",
    "print(\"Ilosc wymairów zmiennych zależnych po optymalizacji: \",size_after_opt)\n",
    "\n",
    "x_train, x_test, y_train, y_test = splitOfData(data, 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: wyniki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "def add_row(table, result, model):\n",
    "    avg_result = [sum(x) / len(x) for x in zip(*result)]\n",
    "    table.add_row([model, round(avg_result[0],5), round(avg_result[1],5), round(avg_result[2],5)])\n",
    "\n",
    "def createSummaryTable(summary_table, results):\n",
    "    add_row(summary_table, results[0], \"Linear Regression\")\n",
    "    add_row(summary_table, results[1], \"Polynominal Regression\")\n",
    "    add_row(summary_table, results[2], \"Decision Tree Regression\")\n",
    "    add_row(summary_table, results[3], \"Random Forrest Regression\")\n",
    "    add_row(summary_table, results[4], \"Voting Regressor\")\n",
    "    add_row(summary_table, results[5], \"Stacking Regressor\")\n",
    "\n",
    "def createSummary(k_fold = 0, grid_search_optimalization = False):\n",
    "    summary_table = PrettyTable(['model', 'MSE', 'r2', 'Experience Variance'])\n",
    "    if (k_fold < 2):\n",
    "        results = prepare_result(grid_search_optimalization)\n",
    "        createSummaryTable(summary_table, results)\n",
    "        print(\"Summary table for result of regression models:\\n\", summary_table, \"\\n\\n\")\n",
    "    else:\n",
    "        results = prepare_result_with_k_fold(k_fold, grid_search_optimalization)\n",
    "        createSummaryTable(summary_table, results)\n",
    "        print(\"Summary table for result of regression models [K_fold: k =\",k_fold,\"]:\\n\", summary_table, \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "createSummary()\n",
    "createSummary(k_fold = 2)\n",
    "createSummary(k_fold = 5)\n",
    "createSummary(k_fold = 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "b8be385d48e05b4f2d5b0c548e070dbf7e445fa615772f44dee8b1f60efa8125"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
